{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import path\n",
    "import datetime\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "sales_train = pd.read_csv(\"sales_train.csv\")\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "shops = pd.read_csv(\"shops.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "items = pd.read_csv(\"items.csv\")\n",
    "item_cat = pd.read_csv(\"item_categories.csv\")\n",
    "\n",
    "\n",
    "GROUPED_TRANSACTION_DATA_FILE = \"grouped_transaction_data.csv\"\n",
    "TRAINING_DATA_FILEPATH = \"training_data.csv\"\n",
    "training_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def YearFromDate(dateStr):\n",
    "    return dateStr.split('.')[2]\n",
    "    \n",
    "#add features\n",
    "if (path.exists(\"data.csv\")):\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "else:  \n",
    "    df = sales_train\n",
    "    # month is de maand, dus jan, feb etc.\n",
    "    df['month'] = df.apply(lambda r: r['date_block_num']%12, axis=1)\n",
    "    df['year'] = df.apply(lambda d: YearFromDate(d['date']), axis = 1)\n",
    "    df = df.drop('item_price', axis = 1) # can be dropped because item_price is just a function of shop_id, month and item_id\n",
    "    df = df.drop('date_block_num', axis = 1) # can be dropped since we have the year and month\n",
    "    df = df.drop('date', axis = 1 ) # can be dropped since we have year and month, don't need day\n",
    "    df.to_csv(\"data.csv\")\n",
    "\n",
    "group_filter = ['shop_id', 'item_id', 'year','month','item_cnt_day']\n",
    "#completing cleaning\n",
    "\n",
    "\n",
    "# sum the transaction in the same month and save the data\n",
    "if (path.exists(TRAINING_DATA_FILEPATH)):\n",
    "    training_data = pd.read_csv(TRAINING_DATA_FILEPATH)[group_filter]\n",
    "else:    \n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    summed_data = df.groupby(['shop_id', 'item_id', 'year','month']).sum().reset_index()\n",
    "    summed_data.to_csv(TRAINING_DATA_FILEPATH)\n",
    "    training_data = summed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the items that weren't sold in training month, but were sold in test month\n",
    "def addMissingTransactions():\n",
    "    for shop in tqdm(X_2['shop_id'].unique()):\n",
    "        for item in X_2[X_2['shop_id'] == shop]['item_id'].unique():\n",
    "            sold_next_month = X_2[(X_2['shop_id'] == shop) & \n",
    "                                  (X_2['item_id'] == item)]\n",
    "            sold_this_month = X_1[(X_1['shop_id'] == shop) & \n",
    "                                  (X_1['item_id'] == item)]\n",
    "            #if items not in training month but in test month\n",
    "            if len(sold_next_month) > 1 and len(sold_this_month) == 0:\n",
    "                print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                closest_month = FindClosestMonth(next_month, shop, item)\n",
    "                print(closest_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "month = 9\n",
    "next_month = (month+1) % 12\n",
    "features = ['shop_id', 'item_id', 'year', 'month']\n",
    "years = training_data['year'].unique()\n",
    "\n",
    "X_1 = training_data[training_data['month'] == month][group_filter]\n",
    "X_train = X_1[(X_1['month'] == month) & (X_1['year'] < max(years))][features]\n",
    "y_train = X_1[(X_1['month'] == month) & (X_1['year'] < max(years))]['item_cnt_day']\n",
    "\n",
    "X_2 = training_data[training_data['month'] == month][group_filter]\n",
    "X_test = X_2[(X_2['month'] == month) & (X_2['year'] == max(years))][features]\n",
    "y_test = X_2[(X_2['month'] == month) & (X_2['year'] == max(years))]['item_cnt_day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93685\n",
      "31531\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.095188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>2</td>\n",
       "      <td>464</td>\n",
       "      <td>-0.913085</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>2</td>\n",
       "      <td>464</td>\n",
       "      <td>1.095188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8168</th>\n",
       "      <td>2</td>\n",
       "      <td>482</td>\n",
       "      <td>-0.913085</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>2</td>\n",
       "      <td>482</td>\n",
       "      <td>1.095188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      shop_id  item_id      year  month\n",
       "8118        2       32  1.095188      9\n",
       "8149        2      464 -0.913085      9\n",
       "8150        2      464  1.095188      9\n",
       "8168        2      482 -0.913085      9\n",
       "8175        2      482  1.095188      9"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: standardize data\n",
    "label_scaler = StandardScaler()\n",
    "label_scaler.fit(np.array(y_train).reshape(-1, 1))\n",
    "y_train = label_scaler.transform(np.array(y_train).reshape(-1,1))\n",
    "\n",
    "year_scaler = StandardScaler()\n",
    "year_scaler.fit(np.array(X_train['year']).reshape(-1, 1))\n",
    "X_train['year'] = year_scaler.transform(np.array(X_train['year']).reshape(-1,1))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_shops = X_train['shop_id'].unique()\n",
    "X_items = X_train['item_id'].unique()\n",
    "X_months = np.array([i for i in range(0,12)])\n",
    "\n",
    "shop_labelEncoder = preprocessing.LabelEncoder().fit(X_shops)\n",
    "item_labelEncoder = preprocessing.LabelEncoder().fit(X_items)\n",
    "month_labelEncoder = preprocessing.LabelEncoder().fit(X_months)\n",
    "\n",
    "shop_labels = dict(zip(X_shops, shop_labelEncoder.transform(X_shops)))\n",
    "item_labels = dict(zip(X_items, item_labelEncoder.transform(X_items)))\n",
    "month_labels = dict(zip(X_months, month_labelEncoder.transform(X_months)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11276\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def vectorize(X):\n",
    "    matrix = np.zeros((len(X), len(X_shops) + len(X_items) + len(X_months) + 3), dtype=np.float32)\n",
    "    i = 0\n",
    "    for n, row in X.iterrows():\n",
    "        matrix[i][shop_labels[row['shop_id']]] = 1\n",
    "        matrix[i][len(shop_labels) + item_labels[row['item_id']]] = 1\n",
    "        matrix[i][len(shop_labels) + len(item_labels)] = row['year']\n",
    "        matrix[i][len(shop_labels) + len(item_labels)+ 3 + month_labels[row['month']]] = 1 # TODO: if i train for 1 month i can remove this\n",
    "        i+=1\n",
    "    return matrix\n",
    "        \n",
    "# matrix = vectorize(pd.DataFrame(X_split[0], columns = ['shop_id', 'item_id', 'year','month']))\n",
    "matrix = vectorize(X_train)\n",
    "print(len(matrix[0]))\n",
    "print(y_train.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 11276\n",
      "Training records: 93685\n",
      "Testing record labels: 93685\n"
     ]
    }
   ],
   "source": [
    "print(\"Features:\", len(matrix[0]))\n",
    "print(\"Training records:\", len(matrix))\n",
    "print(\"Testing record labels:\", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "732/732 [==============================] - 13s 17ms/step - loss: 102.7303\n",
      "Epoch 2/13\n",
      "732/732 [==============================] - 9s 12ms/step - loss: 102.7267: 0s - loss: 103.5\n",
      "Epoch 3/13\n",
      "732/732 [==============================] - 10s 14ms/step - loss: 102.7267\n",
      "Epoch 4/13\n",
      "732/732 [==============================] - 10s 14ms/step - loss: 102.7267\n",
      "Epoch 5/13\n",
      "732/732 [==============================] - 11s 15ms/step - loss: 102.7267\n",
      "Epoch 6/13\n",
      "732/732 [==============================] - 7s 9ms/step - loss: 102.7267\n",
      "Epoch 7/13\n",
      "732/732 [==============================] - 7s 9ms/step - loss: 102.7267\n",
      "Epoch 8/13\n",
      "732/732 [==============================] - 7s 10ms/step - loss: 102.7267\n",
      "Epoch 9/13\n",
      "732/732 [==============================] - 7s 10ms/step - loss: 102.7267\n",
      "Epoch 10/13\n",
      "732/732 [==============================] - 7s 9ms/step - loss: 102.7267\n",
      "Epoch 11/13\n",
      "732/732 [==============================] - 7s 9ms/step - loss: 102.7267\n",
      "Epoch 12/13\n",
      "732/732 [==============================] - 7s 10ms/step - loss: 102.7267\n",
      "Epoch 13/13\n",
      "732/732 [==============================] - 7s 9ms/step - loss: 102.7267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2382fde1a00>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_dim=len(matrix[0]), activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# TODO: should change activation to relu after standardizing data\n",
    "optimizer = RMSprop(lr=0.005)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = optimizer)\n",
    "model.fit(matrix, np.array(y_train), batch_size=128, epochs = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
